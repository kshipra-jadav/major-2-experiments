{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70d0811e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from constants import DATA_PATH, EOS_FILE, SENTINEL_FILE\n",
    "\n",
    "sentinel = pd.read_csv(DATA_PATH / SENTINEL_FILE)\n",
    "eos = pd.read_csv(DATA_PATH / EOS_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df0ec891",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentinel = sentinel[sentinel['SM1 (%)'] != 50]\n",
    "eos = eos[eos['SM1 (%)'] != 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3369e724",
   "metadata": {},
   "outputs": [],
   "source": [
    "from constants import X_cols_eos, X_cols_sentinel, y_col\n",
    "\n",
    "X_sentinel = sentinel[X_cols_sentinel].values\n",
    "X_eos = eos[X_cols_eos].values\n",
    "\n",
    "y_sentinel = sentinel[y_col].values\n",
    "y_eos = eos[y_col].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27d4583c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-17 00:33:19.876596: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5054a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "#     \"16, 1\": tf.keras.Sequential([\n",
    "#     # Input layer\n",
    "#     tf.keras.Input(shape=(2, )),\n",
    "#     tf.keras.layers.Dense(16, activation='relu'),\n",
    "#     tf.keras.layers.Dense(1)\n",
    "# ]),\n",
    "#     \"8, 1\": tf.keras.Sequential([\n",
    "#     # Input layer\n",
    "#     tf.keras.Input(shape=(2, )),\n",
    "#     tf.keras.layers.Dense(8, activation='relu'),\n",
    "#     tf.keras.layers.Dense(1)\n",
    "# ]),\n",
    "#     \"2, 1\": tf.keras.Sequential([\n",
    "#     # Input layer\n",
    "#     tf.keras.Input(shape=(2, )),\n",
    "#     tf.keras.layers.Dense(2, activation='relu'),\n",
    "#     tf.keras.layers.Dense(1)\n",
    "# ]),\n",
    "#     \"4, 1\": tf.keras.Sequential([\n",
    "#     # Input layer\n",
    "#     tf.keras.Input(shape=(2, )),\n",
    "#     tf.keras.layers.Dense(4, activation='relu'),\n",
    "#     tf.keras.layers.Dense(1)\n",
    "# ]),\n",
    "    \"16, Dropout, 8, Dropout\": tf.keras.Sequential([\n",
    "    # Input layer\n",
    "    tf.keras.Input(shape=(2, )),\n",
    "    tf.keras.layers.Dense(16, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.09),\n",
    "    tf.keras.layers.Dense(8, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.09),\n",
    "    tf.keras.layers.Dense(1)\n",
    "]),\n",
    "    \"16, Dropout\": tf.keras.Sequential([\n",
    "    # Input layer\n",
    "    tf.keras.Input(shape=(2, )),\n",
    "    tf.keras.layers.Dense(16, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.1),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56958b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:   2%|▎         | 25/1000 [00:03<02:26,  6.65epoch/s, loss=0.9103, val_loss=0.7280] \n",
      "Epochs:   4%|▍         | 38/1000 [00:05<02:12,  7.27epoch/s, loss=0.4376, val_loss=0.4343]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "16, Dropout, 8, Dropout: {\n",
      "    \"val\": {\n",
      "        \"PICP\": 0.9705882352941176,\n",
      "        \"MPIW\": 40.6114387512207\n",
      "    },\n",
      "    \"test\": {\n",
      "        \"PICP\": 0.9707317073170731,\n",
      "        \"MPIW\": 40.932010650634766\n",
      "    }\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:   6%|▌         | 61/1000 [00:07<01:57,  8.02epoch/s, loss=0.8771, val_loss=0.6899]  \n",
      "Epochs:   2%|▏         | 24/1000 [00:03<02:14,  7.26epoch/s, loss=0.4375, val_loss=0.4342]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "16, Dropout: {\n",
      "    \"val\": {\n",
      "        \"PICP\": 0.9705882352941176,\n",
      "        \"MPIW\": 40.63493728637695\n",
      "    },\n",
      "    \"test\": {\n",
      "        \"PICP\": 0.9707317073170731,\n",
      "        \"MPIW\": 40.94243621826172\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from model_experiments import PredictionIntervalEstimation\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "eos_results = {}\n",
    "\n",
    "for param_string, model in models.items():\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "\n",
    "    exp = PredictionIntervalEstimation(X_eos, y_eos, satellite=\"EOS-04\")\n",
    "    results = exp.run_experiment(model, model_param_string=param_string, optimizer=optimizer, epochs=1000)\n",
    "    eos_results[param_string] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a2cf45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from constants import OUTPUT_PATH\n",
    "import json\n",
    "\n",
    "with open(OUTPUT_PATH / \"pi_estimation\" / \"EOS-04_metrics.json\", \"w\") as f:\n",
    "    json.dump(eos_results, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb7c795b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:   2%|▎         | 25/1000 [00:03<02:16,  7.15epoch/s, loss=0.8827, val_loss=0.7086] \n",
      "Epochs:   2%|▏         | 17/1000 [00:02<02:26,  6.71epoch/s, loss=0.4626, val_loss=0.4769]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/stepWARNING:tensorflow:5 out of the last 25 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7f0c47e46a20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "16, Dropout, 8, Dropout: {\n",
      "    \"val\": {\n",
      "        \"PICP\": 0.9473684210526315,\n",
      "        \"MPIW\": 39.23193359375\n",
      "    },\n",
      "    \"test\": {\n",
      "        \"PICP\": 0.934640522875817,\n",
      "        \"MPIW\": 38.89890670776367\n",
      "    }\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:   6%|▌         | 57/1000 [00:06<01:42,  9.19epoch/s, loss=0.7752, val_loss=0.6654]  \n",
      "Epochs:   2%|▏         | 24/1000 [00:02<01:56,  8.37epoch/s, loss=0.4664, val_loss=0.4768]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/stepWARNING:tensorflow:5 out of the last 21 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7f0c45800c20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "16, Dropout: {\n",
      "    \"val\": {\n",
      "        \"PICP\": 0.9473684210526315,\n",
      "        \"MPIW\": 40.24116134643555\n",
      "    },\n",
      "    \"test\": {\n",
      "        \"PICP\": 0.934640522875817,\n",
      "        \"MPIW\": 39.925601959228516\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from model_experiments import PredictionIntervalEstimation\n",
    "sentinel_results = {}\n",
    "\n",
    "for param_string, model in models.items():\n",
    "    tf.keras.backend.clear_session()\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "\n",
    "    exp = PredictionIntervalEstimation(X_sentinel, y_sentinel, satellite=\"Sentinel-1\")\n",
    "    results = exp.run_experiment(model, model_param_string=param_string, optimizer=optimizer, epochs=1000)\n",
    "    sentinel_results[param_string] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b077dd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from constants import OUTPUT_PATH\n",
    "import json\n",
    "\n",
    "with open(OUTPUT_PATH / \"pi_estimation\" / \"Sentinel-1_metrics.json\", \"w\") as f:\n",
    "    json.dump(sentinel_results, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95754ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-experiments (3.12.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
